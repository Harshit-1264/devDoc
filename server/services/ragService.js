import { QdrantVectorStore } from "@langchain/qdrant";
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters";
import {
  GoogleGenerativeAIEmbeddings,
  ChatGoogleGenerativeAI,
} from "@langchain/google-genai";
import { createStuffDocumentsChain } from "langchain/chains/combine_documents";
import { createRetrievalChain } from "langchain/chains/retrieval";
import { ChatPromptTemplate } from "@langchain/core/prompts";

import "dotenv/config";

let vectorStore;

export const embedAndStoreChunks = async (rawText, docName, collName) => {
  // Split the document text into smaller overlapping chunks
  // This helps keep context while ensuring each chunk fits within embedding limits
  const splitter = new RecursiveCharacterTextSplitter({
    chunkSize: 500, // maximum characters per chunk
    chunkOverlap: 50, // overlapping region between chunks to preserve context
  });

  const chunks = await splitter.splitText(rawText);

  // Generate metadata for each chunk
  // Each metadata object stores the document name and the chunk's index
  // This is useful for identifying which part of which document an embedding came from
  const metadatas = chunks.map((_, i) => ({
    doc: docName, // name of the source document
    index: i, // position of the chunk in that document
  }));

  const embeddings = new GoogleGenerativeAIEmbeddings({
    model: "models/text-embedding-004",
    apiKey: process.env.GOOGLE_API_KEY,
  });

  // Create (or connect to) a Qdrant vector store and upload text embeddings
  vectorStore = await QdrantVectorStore.fromTexts(
    chunks,     // Array of text chunks generated by RecursiveCharacterTextSplitter
    metadatas,  // Metadata for each chunk (e.g., document name and index)
    embeddings, // Embedding model that converts text into numerical vectors
    {
        // Qdrant server configuration
        url: process.env.QDRANT_URL, // Qdrant endpoint (local or cloud)
        apiKey: process.env.QDRANT_API_KEY,    // API key if using Qdrant Cloud
        // // HTTPS configuration (used mainly for self-signed certificates)
        // https: {
        //     rejectUnauthorized: false,  // Ignore SSL certificate errors (for local setups)
        // },
        // Skip compatibility check for Qdrant version differences
        checkCompatibility: false,
        // Collection name to store or retrieve vectors from
        collectionName: collName,
      }
  );
};

export const getAnswerFromChunks = async (question) => {
  if(!vectorStore){
    throw new Error("Vector store not initialized. Upload a document first.");
  }

  const model = new ChatGoogleGenerativeAI({
    model: "gemini-2.5-flash",
    apiKey: process.env.GOOGLE_API_KEY,
  });

  // Create a structured prompt that tells the model how to respond
  const prompt = ChatPromptTemplate.fromTemplate(
    `Hey! I've gone through the following documents to help you out:
    
    {context}
    
    So, based on all that, here's my answer to your question:
    {input}`
  );

  // Combine retrieved document chunks into a single chain for answering
  const combineDocsChain = await createStuffDocumentsChain({
    llm: model,
    prompt,
  });

  // Create a retrieval chain that connects the retriever (Qdrant) with the model
  const chain = await createRetrievalChain({
    combineDocsChain,
    retriever: vectorStore.asRetriever(),
  });

   // Invoke the chain with the user’s question and get the model’s response
  const result = await chain.invoke({ input: question });
  return result.answer;
};